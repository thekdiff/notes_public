* optimization
** wolfe 准则（p33，数值最优化）
+ Armijo 条件（充分下降条件）：目标函数充分下降
+ 曲率条件：步长不至于太小
** Newton-Raphson method
** 牛顿法
+ 二阶泰勒展开，用二次曲面去拟合局部
+ 最速下降法，二次范数的矩阵为Hessian f''(x)时即为牛顿法（而非Hessian的逆）
+ 1. 阻尼牛顿阶段；2. 二次收敛牛顿阶段（纯牛顿阶段，在接近最优点x*的范围）
+ 条件数：矩阵的最大奇异值比最小奇异值
+ 优点：1. 收敛速度快2. 仿射不变性3. 对大规模问题的扩展性好4. 不依赖于算
  法参数
+ 缺点：1. 存储Hessian浪费内存2. 计算逆费时
** 梯度下降法
+ 一阶泰勒展开，用平面去拟合局部
+ 优点：简单
+ 缺点：收敛速度近似线性（f(Xk)-p*以几何序列收敛到零），严重依赖于
  Hessian的条件数，接近最优点时可能会出现震荡（zigzag），因为
  f'T(Xk).f'(X(k+1))=0+ 矩阵求逆时间复杂度下界O(N^3)，矩阵乘法可以低于三次。
+ 高斯消元法极少被用来求逆矩阵，通常只为线性方程组求解，其对于一些矩阵来
  说是稳定的
+ 高斯消元法时间复杂度O(N^3)
** feature-sign
** 超线性收敛
ak -> a0 when k -> inf, lim |ak+1 -a0|/|ak - a0|^p = a, if p > 1 or p ==
1 and a == 0, then it's super-linear, if p == 1 and 0 < a < 1, then it's
linear, if p == 2, it's second order.
** 强凸性
   存在一个m>0，使得函数的Hessian的二次型xT.H.x>=m.xT.x
** 无约束优化条件
** 近端梯度法
** 梯度投影法
** 内点法
** 共轭梯度法
+ 优点：结合了梯度下降法和牛顿法，所需存储量小，收敛快，稳定性高，不需要
  任何外来参数

fuck
